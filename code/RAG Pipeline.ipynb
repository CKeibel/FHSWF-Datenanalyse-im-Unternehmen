{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c88d6fd8-81d6-4165-a408-e379f8f7192a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install -U transformers rank_bm25 evaluate unstructured --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "342e0db2-8c92-4f27-9f5a-600c1acfd4ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.38.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b870cd9-c280-48eb-847c-f920998a629b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/chkei001/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from model import EncoderModel, DecoderModel, BM25Model\n",
    "from store import VectorStore\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sklearn.metrics import ndcg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fefbe59-f3a0-4116-b9dc-0b43653ad905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "279f227517a748389d9b271a87afdbb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0657f5-75f8-43ea-9a86-840909870695",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8097976-b930-407b-a56c-ba32b008cfa6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 130319\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 11873\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset(\"squad_v2\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57daaaab-380b-4627-8371-c2c1a7f3034d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>{'text': ['in the late 1990s'], 'answer_start'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>What areas did Beyonce compete in when she was...</td>\n",
       "      <td>{'text': ['singing and dancing'], 'answer_star...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
       "      <td>{'text': ['2003'], 'answer_start': [526]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context   \n",
       "0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...  \\\n",
       "1  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "2  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "\n",
       "                                            question   \n",
       "0           When did Beyonce start becoming popular?  \\\n",
       "1  What areas did Beyonce compete in when she was...   \n",
       "2  When did Beyonce leave Destiny's Child and bec...   \n",
       "\n",
       "                                             answers  \n",
       "0  {'text': ['in the late 1990s'], 'answer_start'...  \n",
       "1  {'text': ['singing and dancing'], 'answer_star...  \n",
       "2          {'text': ['2003'], 'answer_start': [526]}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
       "      <td>In what country is Normandy located?</td>\n",
       "      <td>{'text': ['France', 'France', 'France', 'Franc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
       "      <td>When were the Normans in Normandy?</td>\n",
       "      <td>{'text': ['10th and 11th centuries', 'in the 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
       "      <td>From which countries did the Norse originate?</td>\n",
       "      <td>{'text': ['Denmark, Iceland and Norway', 'Denm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context   \n",
       "0  The Normans (Norman: Nourmands; French: Norman...  \\\n",
       "1  The Normans (Norman: Nourmands; French: Norman...   \n",
       "2  The Normans (Norman: Nourmands; French: Norman...   \n",
       "\n",
       "                                        question   \n",
       "0           In what country is Normandy located?  \\\n",
       "1             When were the Normans in Normandy?   \n",
       "2  From which countries did the Norse originate?   \n",
       "\n",
       "                                             answers  \n",
       "0  {'text': ['France', 'France', 'France', 'Franc...  \n",
       "1  {'text': ['10th and 11th centuries', 'in the 1...  \n",
       "2  {'text': ['Denmark, Iceland and Norway', 'Denm...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = ds[\"train\"].to_pandas()[[\"context\", \"question\", \"answers\"]]\n",
    "display(df_train.head(3))\n",
    "df_val = ds[\"validation\"].to_pandas()[[\"context\", \"question\", \"answers\"]]\n",
    "display(df_val.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f58e5156-021e-4673-b1e8-67dca3712110",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "extract_answers = lambda answer: \"\" if len(answer['text']) == 0 else answer['text'][0]\n",
    "v_extract_answers = np.vectorize(extract_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8758e3de-9c95-4296-b224-1d069d2c1e46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43498/130319\n",
      "5945/11873\n"
     ]
    }
   ],
   "source": [
    "df_train[\"answers\"] = v_extract_answers(df_train[\"answers\"].values)\n",
    "df_val[\"answers\"] = v_extract_answers(df_val[\"answers\"].values)\n",
    "\n",
    "print(f\"{df_train[df_train['answers'] == ''].shape[0]}/{df_train.shape[0]}\")\n",
    "print(f\"{df_val[df_val['answers'] == ''].shape[0]}/{df_val.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23012a5b-e1d8-4932-9218-afaeac47a04d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_set = df_val[df_val['answers'] != ''].sample(n=500, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c025253-4477-483b-b184-8704b6236466",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def true_binary_relevance(result_idxs, original_id):\n",
    "    return [1 if i == original_id else 0 for i in result_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b69f12-bf9d-493b-b637-100ba46ad3dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bb73a44f473412ba21e8119897985b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "retriever_models = [\n",
    "    \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    \"BAAI/bge-base-en-v1.5\",\n",
    "    \"WhereIsAI/UAE-Large-V1\",\n",
    "    \"BAAI/bge-m3\"\n",
    "]\n",
    "causal_models = [\n",
    "    \"HuggingFaceH4/zephyr-7b-beta\",\n",
    "    \"google/gemma-7b-it\",\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    #\"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "    \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "]\n",
    "\n",
    "retriever_results = []\n",
    "causal_lm_results = []\n",
    "\n",
    "for hybrid in [False, True]:\n",
    "    for retriever_id in retriever_models:\n",
    "        db = VectorStore(retriever_id, hybrid)\n",
    "        db.add_documents(test_set[\"context\"].values.tolist(), test_set.index.tolist())\n",
    "        \n",
    "        for causal_id in causal_models:\n",
    "            causal_lm = DecoderModel(causal_id, device=\"cuda\")\n",
    "            with tqdm(total=len(test_set.question.values)) as pbar:\n",
    "                for document_id, query in zip(test_set.index.tolist(), test_set.question.values):\n",
    "                    best_contexts = \"\"\n",
    "                    best_ndcg = 0\n",
    "                    for distance_metric in [\"cosine\", \"ip\", \"l2\"]:\n",
    "                        results = db.search(query)\n",
    "                        # unpack results\n",
    "                        idxs = [result[\"id\"] for result in results]\n",
    "                        scores = [result[\"score\"] for result in results]\n",
    "                        contexts = [result[\"document\"] for result in results]\n",
    "                        \n",
    "                        # retriever results\n",
    "                        true_relevance = true_binary_relevance(idxs, document_id)\n",
    "                        ndcg = ndcg_score(true_relevance, scores)\n",
    "                        \n",
    "                        retriever_results.append({\n",
    "                            \"model\": retriever_id,\n",
    "                            \"ndcg\": ndcg,\n",
    "                            \"metric\": distance_metric,\n",
    "                            \"hybrid\": \"yes\" if hybrid else \"no\"\n",
    "                        })\n",
    "                        \n",
    "                        best_ndcg = ndcg if ndcg > best_ndcg else best_ndcg\n",
    "                        if ndcg > best_ndcg:\n",
    "                            best_ndcg = ndcg\n",
    "                            best_contexts = contexts\n",
    "                    \n",
    "                    contexts = \"\\n\\n\".join(best_contexts)\n",
    "                    \n",
    "                    \n",
    "                    answer = causal_lm(query, contexts)\n",
    "                    \n",
    "                    causal_lm_results.append(\n",
    "                        {\n",
    "                            \"model\": causal_id,\n",
    "                            \"question\": query,\n",
    "                            \"answer\": answer,\n",
    "                            \"context\": contexts\n",
    "                        }\n",
    "                    )\n",
    "                    pbar.update(1)\n",
    "                del causal_lm\n",
    "                torch.cuda.empty_cache()\n",
    "        del db\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda6c70b-c643-4d8b-be7b-c4c99aab1889",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(causal_models).to_csv(\"causal_lm_results.csv\")\n",
    "pd.DataFrame(causal_models).to_csv(\"retriever_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6eb33a-4bcc-4afc-9062-bc40ab1381d8",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18f21ac-56e2-460b-9a35-4e9262cb9c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu = evaluate.load(\"bleu\") # https://huggingface.co/spaces/evaluate-metric/bleu\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
