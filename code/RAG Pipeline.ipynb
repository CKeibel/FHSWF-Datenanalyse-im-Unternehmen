{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c88d6fd8-81d6-4165-a408-e379f8f7192a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install -U transformers rank_bm25 evaluate unstructured --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "342e0db2-8c92-4f27-9f5a-600c1acfd4ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.38.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "transformers.logging.disable_progress_bar()\n",
    "transformers.logging.set_verbosity_error()\n",
    "\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b870cd9-c280-48eb-847c-f920998a629b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/chkei001/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from model import EncoderModel, DecoderModel, BM25Model\n",
    "from store import VectorStore\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sklearn.metrics import ndcg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fefbe59-f3a0-4116-b9dc-0b43653ad905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf16296d6ce4144a6347a38308cbca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0657f5-75f8-43ea-9a86-840909870695",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8097976-b930-407b-a56c-ba32b008cfa6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = load_dataset(\"squad_v2\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57daaaab-380b-4627-8371-c2c1a7f3034d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_val = ds[\"validation\"].to_pandas()[[\"context\", \"question\", \"answers\"]]\n",
    "display(df_val.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58e5156-021e-4673-b1e8-67dca3712110",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "extract_answers = lambda answer: \"\" if len(answer['text']) == 0 else answer['text'][0]\n",
    "v_extract_answers = np.vectorize(extract_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8758e3de-9c95-4296-b224-1d069d2c1e46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_val[\"answers\"] = v_extract_answers(df_val[\"answers\"].values)\n",
    "\n",
    "print(f\"{df_val[df_val['answers'] == ''].shape[0]}/{df_val.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23012a5b-e1d8-4932-9218-afaeac47a04d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6719</th>\n",
       "      <td>According to PolitiFact the top 400 richest Am...</td>\n",
       "      <td>What did the richest 400 Americans have as chi...</td>\n",
       "      <td>grew up in substantial privilege</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11420</th>\n",
       "      <td>The British failures in North America, combine...</td>\n",
       "      <td>How many of the Pitt's planned expeditions wer...</td>\n",
       "      <td>Two of the expeditions were successful, with F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7963</th>\n",
       "      <td>At the same time the Mongols imported Central ...</td>\n",
       "      <td>Who did the Mongols send to Bukhara as adminis...</td>\n",
       "      <td>Han Chinese and Khitans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9256</th>\n",
       "      <td>The other third of the water flows through the...</td>\n",
       "      <td>Where does the Nederrijn change it's name?</td>\n",
       "      <td>Wijk bij Duurstede</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6749</th>\n",
       "      <td>In Marxian analysis, capitalist firms increasi...</td>\n",
       "      <td>What do capitalist firms substitute equipment ...</td>\n",
       "      <td>labor inputs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4613</th>\n",
       "      <td>The Very high-speed Backbone Network Service (...</td>\n",
       "      <td>What were select locations connected to?</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>When considering computational problems, a pro...</td>\n",
       "      <td>What is a string over a Greek number when cons...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>Closely related fields in theoretical computer...</td>\n",
       "      <td>What is the process that asks a more specific ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4784</th>\n",
       "      <td>A variety of alternatives to the Y. pestis hav...</td>\n",
       "      <td>In what year was Scott and Duncan's research p...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>A Turing machine is a mathematical model of a ...</td>\n",
       "      <td>What is a scientific device that manipulates s...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 context   \n",
       "6719   According to PolitiFact the top 400 richest Am...  \\\n",
       "11420  The British failures in North America, combine...   \n",
       "7963   At the same time the Mongols imported Central ...   \n",
       "9256   The other third of the water flows through the...   \n",
       "6749   In Marxian analysis, capitalist firms increasi...   \n",
       "...                                                  ...   \n",
       "4613   The Very high-speed Backbone Network Service (...   \n",
       "257    When considering computational problems, a pro...   \n",
       "233    Closely related fields in theoretical computer...   \n",
       "4784   A variety of alternatives to the Y. pestis hav...   \n",
       "319    A Turing machine is a mathematical model of a ...   \n",
       "\n",
       "                                                question   \n",
       "6719   What did the richest 400 Americans have as chi...  \\\n",
       "11420  How many of the Pitt's planned expeditions wer...   \n",
       "7963   Who did the Mongols send to Bukhara as adminis...   \n",
       "9256          Where does the Nederrijn change it's name?   \n",
       "6749   What do capitalist firms substitute equipment ...   \n",
       "...                                                  ...   \n",
       "4613           What were select locations connected to?    \n",
       "257    What is a string over a Greek number when cons...   \n",
       "233    What is the process that asks a more specific ...   \n",
       "4784   In what year was Scott and Duncan's research p...   \n",
       "319    What is a scientific device that manipulates s...   \n",
       "\n",
       "                                                 answers  \n",
       "6719                    grew up in substantial privilege  \n",
       "11420  Two of the expeditions were successful, with F...  \n",
       "7963                             Han Chinese and Khitans  \n",
       "9256                                  Wijk bij Duurstede  \n",
       "6749                                        labor inputs  \n",
       "...                                                  ...  \n",
       "4613                                                      \n",
       "257                                                       \n",
       "233                                                       \n",
       "4784                                                      \n",
       "319                                                       \n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_answerable = df_val[df_val['answers'] != ''].sample(n=400, random_state=1)\n",
    "test_set_not_answerable = df_val[df_val['answers'] == ''].sample(n=100, random_state=1)\n",
    "test_set = pd.concat([test_set_answerable, test_set_not_answerable])\n",
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c025253-4477-483b-b184-8704b6236466",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def true_binary_relevance(result_idxs, original_id):\n",
    "    return [1 if i == original_id else 0 for i in result_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49b69f12-bf9d-493b-b637-100ba46ad3dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m causal_lm_results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m causal_id \u001b[38;5;129;01min\u001b[39;00m causal_models:\n\u001b[0;32m---> 22\u001b[0m     causal_lm \u001b[38;5;241m=\u001b[39m \u001b[43mDecoderModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcausal_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m retriever_id \u001b[38;5;129;01min\u001b[39;00m retriever_models:\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m hybrid \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m]:\n",
      "File \u001b[0;32m~/abgabe/model.py:104\u001b[0m, in \u001b[0;36mDecoderModel.__init__\u001b[0;34m(self, model_id, generation_config, device, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_id \u001b[38;5;241m=\u001b[39m model_id\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m device \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat16\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_id)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mchat_template \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_jinja_tempalte()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:561\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    560\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    566\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    567\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:3502\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3493\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3494\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   3495\u001b[0m     (\n\u001b[1;32m   3496\u001b[0m         model,\n\u001b[1;32m   3497\u001b[0m         missing_keys,\n\u001b[1;32m   3498\u001b[0m         unexpected_keys,\n\u001b[1;32m   3499\u001b[0m         mismatched_keys,\n\u001b[1;32m   3500\u001b[0m         offload_index,\n\u001b[1;32m   3501\u001b[0m         error_msgs,\n\u001b[0;32m-> 3502\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   3506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3507\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3509\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3510\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3511\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3512\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3513\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3514\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3515\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3518\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3520\u001b[0m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[1;32m   3521\u001b[0m model\u001b[38;5;241m.\u001b[39mtie_weights()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:3926\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules)\u001b[0m\n\u001b[1;32m   3924\u001b[0m                     hf_quantizer\u001b[38;5;241m.\u001b[39mcreate_quantized_param(model, param, key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, state_dict)\n\u001b[1;32m   3925\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3926\u001b[0m         new_error_msgs, offload_index, state_dict_index \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state_dict_into_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3927\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3928\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3929\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloaded_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3930\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstart_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3931\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3932\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3933\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3934\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3935\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3936\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3937\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3938\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3939\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3940\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3941\u001b[0m \u001b[43m            \u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3942\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3943\u001b[0m         error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_error_msgs\n\u001b[1;32m   3944\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:761\u001b[0m, in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, loaded_state_dict_keys, start_prefix, expected_keys, device_map, offload_folder, offload_index, state_dict_folder, state_dict_index, dtype, hf_quantizer, is_safetensors, keep_in_fp32_modules, unexpected_keys)\u001b[0m\n\u001b[1;32m    759\u001b[0m             set_module_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat32\n\u001b[1;32m    760\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 761\u001b[0m         param \u001b[38;5;241m=\u001b[39m \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;66;03m# For compatibility with PyTorch load_state_dict which converts state dict dtype to existing dtype in model, and which\u001b[39;00m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;66;03m# uses `param.copy_(input_param)` that preserves the contiguity of the parameter in the model.\u001b[39;00m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;66;03m# Reference: https://github.com/pytorch/pytorch/blob/db79ceb110f6646523019a59bbd7b838f43d4a86/torch/nn/modules/module.py#L2040C29-L2040C29\u001b[39;00m\n\u001b[1;32m    766\u001b[0m old_param \u001b[38;5;241m=\u001b[39m model\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "retriever_models = [\n",
    "    \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    \"BAAI/bge-base-en-v1.5\",\n",
    "    \"WhereIsAI/UAE-Large-V1\",\n",
    "    \"BAAI/bge-m3\"\n",
    "]\n",
    "causal_models = [\n",
    "    \"google/gemma-7b-it\",\n",
    "    \"HuggingFaceH4/zephyr-7b-beta\",\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    #\"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "    \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "]\n",
    "\n",
    "retriever_results = []\n",
    "causal_lm_results = []\n",
    "\n",
    "for causal_id in causal_models:\n",
    "    causal_lm = DecoderModel(causal_id, device=\"cuda\")\n",
    "    \n",
    "    for retriever_id in retriever_models:\n",
    "        for hybrid in [True, False]:\n",
    "            db = VectorStore(retriever_id, hybrid)\n",
    "            db.add_documents(test_set[\"context\"].values.tolist(), test_set.index.tolist())\n",
    "\n",
    "            print(f\"Retriever: {retriever_id} - Causal LM: {causal_id} - hybrid: {'yes' if hybrid else 'no'}\")\n",
    "            with tqdm(total=len(test_set.question.values)) as pbar:\n",
    "                for document_id, (_, query, correct_answer) in test_set.iterrows():\n",
    "                    \n",
    "                    best_contexts = \"\"\n",
    "                    best_ndcg = 0\n",
    "                    for distance_metric in [\"cosine\", \"ip\", \"l2\"]:\n",
    "                        results = db.search(query)\n",
    "                        # unpack results\n",
    "                        idxs = [result[\"id\"] for result in results]\n",
    "                        scores = [result[\"score\"] for result in results]\n",
    "                        contexts = [result[\"document\"] for result in results]\n",
    "\n",
    "                        # retriever results\n",
    "                        true_relevance = true_binary_relevance(idxs, document_id)\n",
    "                        ndcg = ndcg_score([true_relevance], [scores])\n",
    "                        \n",
    "                        if correct_answer != \"\":\n",
    "                            retriever_results.append({\n",
    "                                \"model\": retriever_id,\n",
    "                                \"ndcg\": ndcg,\n",
    "                                \"metric\": distance_metric,\n",
    "                                \"hybrid\": \"yes\" if hybrid else \"no\"\n",
    "                            })\n",
    "\n",
    "                        best_ndcg = ndcg if ndcg > best_ndcg else best_ndcg\n",
    "                        if ndcg > best_ndcg:\n",
    "                            best_ndcg = ndcg\n",
    "                            best_contexts = contexts\n",
    "\n",
    "                    contexts = \"\\n\\n\".join(best_contexts)\n",
    "\n",
    "\n",
    "                    answer = causal_lm(query, contexts)\n",
    "\n",
    "                    causal_lm_results.append(\n",
    "                        {\n",
    "                            \"model\": causal_id,\n",
    "                            \"question\": query,\n",
    "                            \"answer\": answer,\n",
    "                            \"context\": contexts,\n",
    "                            \"correct_answer\": correct_answer if correct_answer != \"\" else \"Not answerable from the given context.\"\n",
    "                        }\n",
    "                    )\n",
    "                    pbar.update(1)\n",
    "                del db\n",
    "                torch.cuda.empty_cache()\n",
    "    del causal_lm\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda6c70b-c643-4d8b-be7b-c4c99aab1889",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(causal_lm_results).to_csv(\"causal_lm_results_v2.csv\")\n",
    "pd.DataFrame(retriever_results).to_csv(\"retriever_results_v2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6eb33a-4bcc-4afc-9062-bc40ab1381d8",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18f21ac-56e2-460b-9a35-4e9262cb9c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu = evaluate.load(\"bleu\") # https://huggingface.co/spaces/evaluate-metric/bleu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7671f060-fd39-45c9-8664-1a9be59f6627",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>context</th>\n",
       "      <th>correct_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google/gemma-7b-it</td>\n",
       "      <td>What did the richest 400 Americans have as chi...</td>\n",
       "      <td>&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;eos&gt;</td>\n",
       "      <td></td>\n",
       "      <td>grew up in substantial privilege</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>google/gemma-7b-it</td>\n",
       "      <td>How many of the Pitt's planned expeditions wer...</td>\n",
       "      <td>I do know. The provided text does not contain ...</td>\n",
       "      <td></td>\n",
       "      <td>Two of the expeditions were successful, with F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>google/gemma-7b-it</td>\n",
       "      <td>Who did the Mongols send to Bukhara as adminis...</td>\n",
       "      <td>Sure, here is the answer to the question:\\n\\nT...</td>\n",
       "      <td></td>\n",
       "      <td>Han Chinese and Khitans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>google/gemma-7b-it</td>\n",
       "      <td>Where does the Nederrijn change it's name?</td>\n",
       "      <td>I do know. The text does not provide informati...</td>\n",
       "      <td></td>\n",
       "      <td>Wijk bij Duurstede</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>google/gemma-7b-it</td>\n",
       "      <td>What do capitalist firms substitute equipment ...</td>\n",
       "      <td>Sure, here is the answer to the question:\\n\\nI...</td>\n",
       "      <td></td>\n",
       "      <td>labor inputs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10995</th>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>What were select locations connected to?</td>\n",
       "      <td>I donot have enough context to provide an answ...</td>\n",
       "      <td></td>\n",
       "      <td>Not answerable from the given context.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10996</th>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>What is a string over a Greek number when cons...</td>\n",
       "      <td>I donot know. The context does not provide eno...</td>\n",
       "      <td></td>\n",
       "      <td>Not answerable from the given context.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10997</th>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>What is the process that asks a more specific ...</td>\n",
       "      <td>I donotknow. The context provided does not con...</td>\n",
       "      <td></td>\n",
       "      <td>Not answerable from the given context.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10998</th>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>In what year was Scott and Duncan's research p...</td>\n",
       "      <td>I donot have access to the specific context pr...</td>\n",
       "      <td></td>\n",
       "      <td>Not answerable from the given context.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10999</th>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>What is a scientific device that manipulates s...</td>\n",
       "      <td>I donotknow. The context provided does not con...</td>\n",
       "      <td></td>\n",
       "      <td>Not answerable from the given context.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    model   \n",
       "0                      google/gemma-7b-it  \\\n",
       "1                      google/gemma-7b-it   \n",
       "2                      google/gemma-7b-it   \n",
       "3                      google/gemma-7b-it   \n",
       "4                      google/gemma-7b-it   \n",
       "...                                   ...   \n",
       "10995  mistralai/Mistral-7B-Instruct-v0.2   \n",
       "10996  mistralai/Mistral-7B-Instruct-v0.2   \n",
       "10997  mistralai/Mistral-7B-Instruct-v0.2   \n",
       "10998  mistralai/Mistral-7B-Instruct-v0.2   \n",
       "10999  mistralai/Mistral-7B-Instruct-v0.2   \n",
       "\n",
       "                                                question   \n",
       "0      What did the richest 400 Americans have as chi...  \\\n",
       "1      How many of the Pitt's planned expeditions wer...   \n",
       "2      Who did the Mongols send to Bukhara as adminis...   \n",
       "3             Where does the Nederrijn change it's name?   \n",
       "4      What do capitalist firms substitute equipment ...   \n",
       "...                                                  ...   \n",
       "10995          What were select locations connected to?    \n",
       "10996  What is a string over a Greek number when cons...   \n",
       "10997  What is the process that asks a more specific ...   \n",
       "10998  In what year was Scott and Duncan's research p...   \n",
       "10999  What is a scientific device that manipulates s...   \n",
       "\n",
       "                                                  answer context   \n",
       "0                                   <pad><pad><pad><eos>          \\\n",
       "1      I do know. The provided text does not contain ...           \n",
       "2      Sure, here is the answer to the question:\\n\\nT...           \n",
       "3      I do know. The text does not provide informati...           \n",
       "4      Sure, here is the answer to the question:\\n\\nI...           \n",
       "...                                                  ...     ...   \n",
       "10995  I donot have enough context to provide an answ...           \n",
       "10996  I donot know. The context does not provide eno...           \n",
       "10997  I donotknow. The context provided does not con...           \n",
       "10998  I donot have access to the specific context pr...           \n",
       "10999  I donotknow. The context provided does not con...           \n",
       "\n",
       "                                          correct_answer  \n",
       "0                       grew up in substantial privilege  \n",
       "1      Two of the expeditions were successful, with F...  \n",
       "2                                Han Chinese and Khitans  \n",
       "3                                     Wijk bij Duurstede  \n",
       "4                                           labor inputs  \n",
       "...                                                  ...  \n",
       "10995             Not answerable from the given context.  \n",
       "10996             Not answerable from the given context.  \n",
       "10997             Not answerable from the given context.  \n",
       "10998             Not answerable from the given context.  \n",
       "10999             Not answerable from the given context.  \n",
       "\n",
       "[11000 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(causal_lm_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1599bb8-3bfa-4e5c-bf4a-63eeb39ed50d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>metric</th>\n",
       "      <th>hybrid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>cosine</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>ip</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>l2</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>cosine</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>ip</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17995</th>\n",
       "      <td>WhereIsAI/UAE-Large-V1</td>\n",
       "      <td>0.63093</td>\n",
       "      <td>ip</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17996</th>\n",
       "      <td>WhereIsAI/UAE-Large-V1</td>\n",
       "      <td>0.63093</td>\n",
       "      <td>l2</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17997</th>\n",
       "      <td>WhereIsAI/UAE-Large-V1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>cosine</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17998</th>\n",
       "      <td>WhereIsAI/UAE-Large-V1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>ip</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17999</th>\n",
       "      <td>WhereIsAI/UAE-Large-V1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>l2</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        model     ndcg  metric hybrid\n",
       "0      sentence-transformers/all-MiniLM-L6-v2  1.00000  cosine     no\n",
       "1      sentence-transformers/all-MiniLM-L6-v2  1.00000      ip     no\n",
       "2      sentence-transformers/all-MiniLM-L6-v2  1.00000      l2     no\n",
       "3      sentence-transformers/all-MiniLM-L6-v2  1.00000  cosine     no\n",
       "4      sentence-transformers/all-MiniLM-L6-v2  1.00000      ip     no\n",
       "...                                       ...      ...     ...    ...\n",
       "17995                  WhereIsAI/UAE-Large-V1  0.63093      ip     no\n",
       "17996                  WhereIsAI/UAE-Large-V1  0.63093      l2     no\n",
       "17997                  WhereIsAI/UAE-Large-V1  1.00000  cosine     no\n",
       "17998                  WhereIsAI/UAE-Large-V1  1.00000      ip     no\n",
       "17999                  WhereIsAI/UAE-Large-V1  1.00000      l2     no\n",
       "\n",
       "[18000 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(retriever_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e57dca6-b3c0-44ad-90e1-2d2625279816",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "552d061a-814b-4702-a98c-6a9f1d6c4361",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"retriever_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc88546b-b14f-4f29-8fbd-2c50e9fbb5f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8272514504055871"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"model\"]==\"sentence-transformers/all-MiniLM-L6-v2\"][\"ndcg\"].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
